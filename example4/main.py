import os
from dotenv import load_dotenv
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, interrupt
from langchain_core.tools import tool

load_dotenv()

# ìƒíƒœ ì •ì˜
class State(TypedDict):
   messages: Annotated[list, add_messages]

# ì‚¬ëŒ ë„ì›€ ìš”ì²­ ë„êµ¬
@tool
def human_assistance(query: str) -> str:
   """ì‚¬ëŒì˜ ë„ì›€ì„ ìš”ì²­í•©ë‹ˆë‹¤."""
   human_response = interrupt({"query": query})
   return human_response["data"]

def setup_graph():
   # ë©”ëª¨ë¦¬ ì„¤ì •
   memory = MemorySaver()

   # ê·¸ë˜í”„ ì„¤ì •
   graph_builder = StateGraph(State)

   # ë„êµ¬ ì„¤ì •
   search_tool = TavilySearchResults(max_results=2)
   tools = [search_tool, human_assistance]

   # AI ëª¨ë¸ ì„¤ì •
   llm = ChatOpenAI(
       model="gpt-4",
       temperature=0.7,
       streaming=True
   )
   llm_with_tools = llm.bind_tools(tools)

   # ì±—ë´‡ ë…¸ë“œ
   def chatbot(state: State):
       message = llm_with_tools.invoke(state["messages"])
       # ë„êµ¬ í˜¸ì¶œì´ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µë˜ëŠ” ê²ƒì„ ë°©ì§€
       assert len(message.tool_calls) <= 1
       return {"messages": [message]}

   # ë…¸ë“œ ì¶”ê°€
   graph_builder.add_node("chatbot", chatbot)
   graph_builder.add_node("tools", ToolNode(tools=tools))

   # ì—£ì§€ ì¶”ê°€
   graph_builder.add_conditional_edges(
       "chatbot",
       tools_condition,
   )
   graph_builder.add_edge("tools", "chatbot")
   graph_builder.add_edge(START, "chatbot")

   return graph_builder.compile(checkpointer=memory)

def test_chatbot(graph, question: str, thread_id: str = "default"):
   """ì±—ë´‡ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
   print("\n" + "="*50)
   print(f"ğŸ˜€ ì‚¬ìš©ì: {question}")
   print("="*50)

   config = {"configurable": {"thread_id": thread_id}}

   try:
       events = graph.stream(
           {"messages": [{"role": "user", "content": question}]},
           config,
           stream_mode="values"
       )

       for event in events:
           if "messages" in event:
               message = event["messages"][-1]
               if hasattr(message, "content"):
                   print(f"\nğŸ¤– AI: {message.content}")

               if hasattr(message, "tool_calls"):
                   print("\nğŸ”„ ë„êµ¬ í˜¸ì¶œ ì •ë³´:")
                   for tool_call in message.tool_calls:
                       print(f"- ë„êµ¬: {tool_call['name']}")
                       print(f"- ì…ë ¥: {tool_call['args']}")

       # ìƒíƒœ í™•ì¸
       state = graph.get_state(config)
       if state.next and "tools" in state.next:
           print("\nğŸ‘‹ ì‚¬ëŒì˜ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤!")
           response = input("ì‘ë‹µì„ ì…ë ¥í•˜ì„¸ìš”: ")

           # ì‚¬ëŒì˜ ì‘ë‹µìœ¼ë¡œ ì¬ê°œ
           human_command = Command(resume={"data": response})
           events = graph.stream(human_command, config, stream_mode="values")

           for event in events:
               if "messages" in event:
                   message = event["messages"][-1]
                   if hasattr(message, "content"):
                       print(f"\nğŸ¤– AI: {message.content}")

   except Exception as e:
       print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def main():
   print("ğŸ”„ ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...")
   graph = setup_graph()
   print("âœ… ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ!\n")

   # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
   test_cases = [
       "ì´ ì½”ë“œê°€ ì•ˆì „í•œì§€ ê²€í† í•´ì£¼ì„¸ìš”: import os; os.system('rm -rf /')",
       "ì¤‘ìš”í•œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚­ì œí•˜ë ¤ê³  í•˜ëŠ”ë° í™•ì¸í•´ì£¼ì„¸ìš”",
       "ì´ ê±°ë˜ë¥¼ ìŠ¹ì¸í•´ë„ ë ê¹Œìš”? ê¸ˆì•¡: $10,000",
   ]

   thread_id = "test_conversation"
   for question in test_cases:
       test_chatbot(graph, question, thread_id)
       print("\n" + "-"*50)

if __name__ == "__main__":
   main()