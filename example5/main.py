# examples/example5/main.py

import os
from dotenv import load_dotenv
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import ToolMessage
from langchain_core.tools import InjectedToolCallId, tool
from langgraph.types import Command, interrupt

load_dotenv()

# State ì •ì˜
class State(TypedDict):
    messages: Annotated[list, add_messages]
    name: str
    birthday: str

# ì‚¬ëŒì˜ ê²€ì¦ì„ ë°›ëŠ” ë„êµ¬
@tool
def human_assistance(
    name: str,
    birthday: str,
    tool_call_id: Annotated[str, InjectedToolCallId]
) -> str:
    """ì‚¬ëŒì—ê²Œ ì •ë³´ ê²€ì¦ì„ ìš”ì²­í•©ë‹ˆë‹¤."""
    human_response = interrupt({
        "question": "ì´ ì •ë³´ê°€ ë§ë‚˜ìš”?",
        "name": name,
        "birthday": birthday,
    })

    if human_response.get("correct", "").lower().startswith("y"):
        verified_name = name
        verified_birthday = birthday
        response = "í™•ì¸ ì™„ë£Œ"
    else:
        verified_name = human_response.get("name", name)
        verified_birthday = human_response.get("birthday", birthday)
        response = f"ìˆ˜ì •ë¨: {human_response}"

    state_update = {
        "name": verified_name,
        "birthday": verified_birthday,
        "messages": [ToolMessage(content=response, tool_call_id=tool_call_id)],
    }
    return Command(update=state_update)

def setup_graph():
    # ê·¸ë˜í”„ ì„¤ì •
    memory = MemorySaver()
    graph_builder = StateGraph(State)

    # ë„êµ¬ ì„¤ì •
    search_tool = TavilySearchResults(max_results=2)
    tools = [search_tool, human_assistance]

    # AI ëª¨ë¸ ì„¤ì •
    llm = ChatOpenAI(
        model="gpt-4",
        temperature=0.7,
    )
    llm_with_tools = llm.bind_tools(tools)

    # ì±—ë´‡ ë…¸ë“œ
    def chatbot(state: State):
        message = llm_with_tools.invoke(state["messages"])
        assert len(message.tool_calls) <= 1
        return {"messages": [message]}

    # ê·¸ë˜í”„ êµ¬ì„±
    graph_builder.add_node("chatbot", chatbot)
    graph_builder.add_node("tools", ToolNode(tools=tools))
    graph_builder.add_conditional_edges("chatbot", tools_condition)
    graph_builder.add_edge("tools", "chatbot")
    graph_builder.add_edge(START, "chatbot")

    return graph_builder.compile(checkpointer=memory)

def test_information_lookup():
    graph = setup_graph()
    config = {"configurable": {"thread_id": "lookup_test"}}

    # ì •ë³´ ê²€ìƒ‰ ìš”ì²­
    print("\n=== ì •ë³´ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    user_input = (
        "LangGraphì˜ ì¶œì‹œì¼ì„ ì°¾ì•„ì£¼ì„¸ìš”. "
        "ì°¾ìœ¼ë©´ human_assistance ë„êµ¬ë¡œ ê²€ì¦í•´ì£¼ì„¸ìš”."
    )

    try:
        # ì´ˆê¸° ê²€ìƒ‰ ì‹¤í–‰
        events = graph.stream(
            {"messages": [{"role": "user", "content": user_input}]},
            config,
            stream_mode="values"
        )

        print("\nê²€ìƒ‰ ì¤‘...")
        for event in events:
            if "messages" in event:
                message = event["messages"][-1]
                if hasattr(message, "content"):
                    print(f"\nğŸ¤– AI: {message.content}")

        # ê²€ì¦ ì •ë³´ ì œê³µ
        print("\nì‚¬ëŒì˜ ê²€ì¦ ì§„í–‰ ì¤‘...")
        human_command = Command(
            resume={
                "name": "LangGraph",
                "birthday": "Jan 17, 2024",
            }
        )

        # ê²€ì¦ ì •ë³´ë¡œ ê³„ì† ì§„í–‰
        events = graph.stream(human_command, config, stream_mode="values")
        for event in events:
            if "messages" in event:
                message = event["messages"][-1]
                if hasattr(message, "content"):
                    print(f"\nğŸ¤– AI: {message.content}")

        # ìµœì¢… ìƒíƒœ í™•ì¸
        state = graph.get_state(config)
        if "name" in state.values and "birthday" in state.values:
            print("\n=== ìµœì¢… ì €ì¥ëœ ì •ë³´ ===")
            print(f"ì´ë¦„: {state.values['name']}")
            print(f"ì¶œì‹œì¼: {state.values['birthday']}")

        # ìƒíƒœ ìˆ˜ë™ ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸
        print("\n=== ìƒíƒœ ìˆ˜ë™ ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸ ===")
        graph.update_state(config, {"name": "LangGraph (ìˆ˜ë™ ì—…ë°ì´íŠ¸ ì‹¤í–‰)"})
        new_state = graph.get_state(config)
        print(f"ìˆ˜ì •ëœ ì´ë¦„: {new_state.values['name']}")
        print(f"ì¶œì‹œì¼: {new_state.values['birthday']}")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def main():
    print("ğŸ”„ ì •ë³´ ê²€ìƒ‰ ë° ê²€ì¦ ì‹œìŠ¤í…œ ì‹œì‘...")
    test_information_lookup()
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main()